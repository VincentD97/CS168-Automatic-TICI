{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic TICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import KFold\n",
    "import skimage.filters as filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Feature Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray2binary(image_set):\n",
    "    thresholds = list(map(filters.threshold_li, image_set))\n",
    "    # When an image's frequency is too low, filters.threshold_li may \n",
    "    # cause a divide-by-zero RuntimeWarning, and the corresponding\n",
    "    # threshold will be 0. So we need to remove zeros in thresholds.\n",
    "#     thresholds = list(filter(lambda th: th > 0, thresholds))\n",
    "    # print(thresholds)\n",
    "    \n",
    "    min_threshold = min(thresholds)\n",
    "    # print('min_threshold = ', min_threshold)\n",
    "    result = []\n",
    "    for i in range(len(image_set)):\n",
    "        result.append(image_set[i] > thresholds[i])\n",
    "    return result\n",
    "#     return np.array(list(map(lambda img : img > min_threshold, image_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_middle_artery(image_set):\n",
    "    # Assume all the images in an image set have the same dimensions.\n",
    "    image_count, image_height, image_width = np.shape(image_set)\n",
    "    result = []\n",
    "    for image in image_set:\n",
    "        # Only consider the middle 1/4 of the upper 1/4 image.\n",
    "        middle_section = image[0:int(image_height/4), int(image_width*3/8):int(image_width*5/8)]\n",
    "        # plt.figure()\n",
    "        # plt.imshow(middle_section, cmap='gray')\n",
    "        \n",
    "        summary = np.array(list(map(all, middle_section)))\n",
    "        # print(np.count_nonzero(summary))\n",
    "\n",
    "        # summary = np.tile(summary[:, np.newaxis], 200)\n",
    "        result.append(summary)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_image(image_set):\n",
    "    binary_image_set = gray2binary(image_set)\n",
    "    middle_artery_summary_image_set = summarize_middle_artery(binary_image_set)\n",
    "    image_count, image_height = np.shape(middle_artery_summary_image_set)\n",
    "    \n",
    "    flagOn = False\n",
    "    previous_nonzeroCount = -1\n",
    "    for i in range(image_count):\n",
    "        nonzeroCount = np.count_nonzero(middle_artery_summary_image_set[i])\n",
    "        if flagOn and nonzeroCount < image_height/2:\n",
    "            return image_set[i]\n",
    "        elif previous_nonzeroCount >= 0 and nonzeroCount - previous_nonzeroCount > image_height/2:\n",
    "            flagOn = True\n",
    "        previous_nonzeroCount = nonzeroCount\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & extract images and TICI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 files found in the data directory '/Users/ceciliawang/Desktop/UCLA/Senior Year/Spring 2019/CS 168/CS168-Automatic-TICI/data'.\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the data directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "# Get a list of full paths of all mat files in the data directory.\n",
    "for root, _dirs, files in os.walk(data_dir):\n",
    "    files = list(filter(lambda fname: fname.lower().endswith('.mat'), sorted(files)))\n",
    "nfiles = len(files)\n",
    "print('{} files found in the data directory \\'{}\\'.'.format(nfiles, data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the data_dir and a file name, extract an image from\n",
    "# the set of images and the TICI score.\n",
    "# By default, nothing is printed.\n",
    "# If verbose=1, print the keys of the mat file content (which is a dictionary).\n",
    "# If verbose=2, print the 3 TICI scores for debugging purpose.\n",
    "def extract_data_file(data_dir, fname, verbose=False):\n",
    "    content = loadmat(os.path.join(data_dir, fname))\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('{}\\tkeys={}'.format(fname, sorted(content.keys())))\n",
    "    if verbose == 2:\n",
    "        print('{}\\t\\tTICI_Dr1={}\\tTICI_Dr2={}\\tTICI_report={}'.format(fname, content['TICI_Dr1'], content['TICI_Dr2'], content['TICI_report']))\n",
    "\n",
    "    raw_image_set, TICI = content['X'], content['TICI_report']\n",
    "    # Originally, raw_image_set[:, :, k] is the kth image.\n",
    "    # Reorder the dimensions such that raw_image_set[k, :, :] is the kth image.\n",
    "    image_set = np.transpose(raw_image_set, (2, 0, 1))\n",
    "    # Only one image from each image set is selected to be fed into the model.\n",
    "    # For simplicity, the image in the middle of each image set is selected just for now.\n",
    "    count, _, __ = np.shape(image_set)\n",
    "    image = choose_image(image_set)\n",
    "    return image, TICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fractals_1.mat\tkeys=['TICI_Dr1', 'TICI_Dr2', 'TICI_report', 'X', '__globals__', '__header__', '__version__']\n",
      "(1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# From the first mat file, learn the structure and the image set dimensions.\n",
    "# Assume that all mat files have the same structure and that all the images \n",
    "# in each image set have the same dimensions, though each image sets may\n",
    "# contain various number of images.\n",
    "sample_image, sample_TICI = extract_data_file(data_dir, files[0], verbose=1)\n",
    "image_shape = sample_image.shape\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fractals_1.mat\t\tTICI_Dr1=['2b']\tTICI_Dr2=['2b']\tTICI_report=['2a']\n",
      "fractals_10.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2a']\n",
      "fractals_100.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[3]]\n",
      "fractals_101.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_102.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2b']\n",
      "fractals_103.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[nan]]\n",
      "fractals_104.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2b']\n",
      "fractals_105.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_106.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_107.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2a']\n"
     ]
    }
   ],
   "source": [
    "# For debugging purpose, print the 3 TICI scores for the first 10 mat files.\n",
    "for n in range(10):\n",
    "    _, _ = extract_data_file(data_dir, files[n], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 201 done\n",
      "10 / 201 done\n",
      "20 / 201 done\n",
      "30 / 201 done\n",
      "40 / 201 done\n",
      "50 / 201 done\n",
      "60 / 201 done\n",
      "70 / 201 done\n",
      "80 / 201 done\n",
      "90 / 201 done\n",
      "100 / 201 done\n",
      "110 / 201 done\n",
      "120 / 201 done\n",
      "130 / 201 done\n",
      "140 / 201 done\n",
      "150 / 201 done\n",
      "160 / 201 done\n",
      "170 / 201 done\n",
      "180 / 201 done\n",
      "190 / 201 done\n",
      "200 / 201 done\n",
      "(201, 1024, 1024)\n",
      "['2a', '2a', '3', '0', '2b', 'nan', '2b', '0', '0', '2a', '2b', '2a', '2a', '2b', '0', '2b', '2b', '0', 'nan', '3', 'nan', '2b', '1', '2b', '2a', '0', '2b', '2b', 'nan', '0', '2a', '0', '2a', '3', '2b', '2b', '2a', 'nan', '2b', 'nan', '0', '2a', '2a', '3', '2b', '2b', '0', '2b', '2b', '2b', '2a', '2a', '2b', '3', '2a', '2a', '2b', '2a', '2a', '2b', '2a', '2b', '2b', '0', '2a', '1', '2a', '2b', '3', '2a', '2a', '3', '0', '2a', '2a', '2b', '2b', '2a', '2a', '2b', '1', '2b', '3', '2a', '2b', '2a', '2b', '2b', '2a', '2a', 'nan', '0', '3', '2b', '0', '0', '0 (bilateral MCA)', '0', '0', '2b', '3', '3', '2b', '0', '2a', '2a', '0', '2a', '2b', '2a', '2b', '2b', '2b', '2b', '2b', '2a', '2b', '2a?', '2b', '0', '2a', 'nan', '2b', '2b', '2b', 'nan', '2a', '2a', '1', '2b', '2a', '1', '2b', '1', '1', '2b', '2a', 'nan', '2b', '2a', '2b', '2b', '2a', '2b', '2b', 'nan', '2b', '0', '2b', '0', '2b', '1', 'nan', '3', '2b', '2a', '2a', '2a', 'nan', '2b', '0', '3', 'nan', '0', '2b', '2a', '2b', '2b', '2b', '3', 'nan', '3', 'nan', 'nan', '2b', '2b', '3', '2a', '2a', '2b', '2b', '0', '0', '2a', '2a', '0', '2b', '2a', '2a', '2b', '2b', 'nan', 'nan', '0', 'nan', '2b', '2b', '2a', '2b', '2b', '2a']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list for images and a numpy arrays for \n",
    "# corresponding TICI scores. Assume all images have \n",
    "# the same dimensions. The TICI score in each \n",
    "images = []\n",
    "TICI_strings = []\n",
    "\n",
    "# Extract image and TICI information for all mat files.\n",
    "for n in range(nfiles):\n",
    "    # Print the extracting progress.\n",
    "    if n % 10 == 0:\n",
    "        print('{} / {} done'.format(n, nfiles))\n",
    "    image, TICI = extract_data_file(data_dir, files[n])\n",
    "    images.append(image)\n",
    "    # The TICI scores in the mat files are in the form of \n",
    "    # nested np.ndarray's of either strings, numbers, of nan.\n",
    "    # e.g., ['2a'], [[3]], [[nan]]. With assumption of \n",
    "    # this structure, simplify TICI before append it to TICIs.\n",
    "    while isinstance(TICI, np.ndarray):\n",
    "        TICI = TICI[0] if len(TICI) > 0 else ''\n",
    "    TICI_strings.append(str(TICI))\n",
    "\n",
    "print(np.shape(images))\n",
    "print(TICI_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat TICI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 4, 0, 3, 5, 3, 0, 0, 2, 3, 2, 2, 3, 0, 3, 3, 0, 5, 4, 5, 3, 1, 3, 2, 0, 3, 3, 5, 0, 2, 0, 2, 4, 3, 3, 2, 5, 3, 5, 0, 2, 2, 4, 3, 3, 0, 3, 3, 3, 2, 2, 3, 4, 2, 2, 3, 2, 2, 3, 2, 3, 3, 0, 2, 1, 2, 3, 4, 2, 2, 4, 0, 2, 2, 3, 3, 2, 2, 3, 1, 3, 4, 2, 3, 2, 3, 3, 2, 2, 5, 0, 4, 3, 0, 0, 0, 0, 0, 3, 4, 4, 3, 0, 2, 2, 0, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 0, 2, 5, 3, 3, 3, 5, 2, 2, 1, 3, 2, 1, 3, 1, 1, 3, 2, 5, 3, 2, 3, 3, 2, 3, 3, 5, 3, 0, 3, 0, 3, 1, 5, 4, 3, 2, 2, 2, 5, 3, 0, 4, 5, 0, 3, 2, 3, 3, 3, 4, 5, 4, 5, 5, 3, 3, 4, 2, 2, 3, 3, 0, 0, 2, 2, 0, 3, 2, 2, 3, 3, 5, 5, 0, 5, 3, 3, 2, 3, 3, 2]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The number of different TICI scores.\n",
    "# Including 0, 1, 2a, 2b, 3, nan.\n",
    "num_TICI_classes = 6\n",
    "\n",
    "# Convert a TICI string to a number\n",
    "def map_TICI_str_to_num(TICI):\n",
    "    relation = {\n",
    "        '0': 0,\n",
    "        '1': 1,\n",
    "        '2a': 2,\n",
    "        '2b': 3,\n",
    "        '3': 4,\n",
    "        'nan': 5,\n",
    "        '0 (bilateral MCA)': 0,\n",
    "        '2a?': 2\n",
    "    }\n",
    "    return relation[TICI]\n",
    "\n",
    "# Convert a numerical encoded TICI to a string\n",
    "def map_TICI_num_to_str(label):\n",
    "    relation = ['0', '1', '2a', '2b', '3', 'nan']\n",
    "    return relation[label]\n",
    "\n",
    "# Convert TICI scores in the form of strings to numeric labels before fed to the model.\n",
    "TICI_nums = list(map(map_TICI_str_to_num, TICI_strings))\n",
    "print(TICI_nums)\n",
    "\n",
    "# Convert the array of integer labels (0 ~ num_TICI_classes-1) to an array of \n",
    "# one-hot (aka one-of-K) encoded labels, for better accuracy.\n",
    "TICI_one_hot = tf.keras.utils.to_categorical(TICI_nums, num_TICI_classes)\n",
    "print(TICI_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 1024, 1024, 32)    832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1572870   \n",
      "=================================================================\n",
      "Total params: 1,625,094\n",
      "Trainable params: 1,625,030\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with tensorflow.keras.\n",
    "# The general idea is to reduce the size by maxpooling and \n",
    "# extract more features with convolutions of an increasing \n",
    "# number of filters.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 5, padding='same', activation='relu', \n",
    "                        input_shape=(image_shape[0], image_shape[1], 1)),  # learn why the 1 is required...\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((4, 4), (4, 4), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(num_TICI_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add one dimension to the images input for channels.\n",
    "images_as_model_input = np.array(images).reshape(nfiles, image_shape[0], image_shape[1], 1)\n",
    "print(images_as_model_input.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 51 samples\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 77s 513ms/sample - loss: 0.8794 - accuracy: 0.7000 - val_loss: 13.4991 - val_accuracy: 0.1176\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 75s 499ms/sample - loss: 0.7298 - accuracy: 0.7267 - val_loss: 12.5254 - val_accuracy: 0.1176\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 73s 486ms/sample - loss: 0.5809 - accuracy: 0.8133 - val_loss: 13.5854 - val_accuracy: 0.1176\n",
      "Train on 151 samples, validate on 50 samples\n",
      "Epoch 1/3\n",
      "151/151 [==============================] - 72s 479ms/sample - loss: 0.6536 - accuracy: 0.7550 - val_loss: 18.9371 - val_accuracy: 0.0200\n",
      "Epoch 2/3\n",
      "151/151 [==============================] - 77s 511ms/sample - loss: 0.4738 - accuracy: 0.8477 - val_loss: 18.3682 - val_accuracy: 0.1200\n",
      "Epoch 3/3\n",
      "151/151 [==============================] - 75s 498ms/sample - loss: 0.4750 - accuracy: 0.8212 - val_loss: 19.4057 - val_accuracy: 0.3000\n",
      "Train on 151 samples, validate on 50 samples\n",
      "Epoch 1/3\n",
      "151/151 [==============================] - 77s 508ms/sample - loss: 0.5039 - accuracy: 0.8079 - val_loss: 19.0698 - val_accuracy: 0.4600\n",
      "Epoch 2/3\n",
      "151/151 [==============================] - 76s 506ms/sample - loss: 0.3599 - accuracy: 0.8808 - val_loss: 9.4485 - val_accuracy: 0.4600\n",
      "Epoch 3/3\n",
      "151/151 [==============================] - 74s 489ms/sample - loss: 0.2836 - accuracy: 0.9205 - val_loss: 13.5772 - val_accuracy: 0.0200\n",
      "Train on 151 samples, validate on 50 samples\n",
      "Epoch 1/3\n",
      "151/151 [==============================] - 76s 504ms/sample - loss: 0.2589 - accuracy: 0.9139 - val_loss: 9.5685 - val_accuracy: 0.1000\n",
      "Epoch 2/3\n",
      "151/151 [==============================] - 76s 505ms/sample - loss: 0.1788 - accuracy: 0.9536 - val_loss: 9.9964 - val_accuracy: 0.1000\n",
      "Epoch 3/3\n",
      "151/151 [==============================] - 73s 482ms/sample - loss: 0.1396 - accuracy: 0.9669 - val_loss: 6.9929 - val_accuracy: 0.1400\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "for train_index, test_index in kf.split(images_as_model_input):\n",
    "    x_train, x_val = images_as_model_input[train_index], images_as_model_input[test_index]\n",
    "    y_train, y_val = TICI_one_hot[train_index], TICI_one_hot[test_index]\n",
    "    \n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=10, ##################### TODO\n",
    "        epochs=3, ##################### TODO\n",
    "        verbose=1, # progress bar\n",
    "        validation_data=(x_val, y_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
