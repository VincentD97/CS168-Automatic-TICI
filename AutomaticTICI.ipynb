{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic TICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & extract images and TICI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 files found in the data directory '/Users/vincentdong/Documents/College/UCLA/14 Spring 2019/CS 168 - Computational Methods for Medical Imaging/Project/CS168-Automatic-TICI/data'.\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the data directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "# Get a list of full paths of all mat files in the data directory.\n",
    "for root, _dirs, files in os.walk(data_dir):\n",
    "    files = list(filter(lambda fname: fname.lower().endswith('.mat'), sorted(files)))\n",
    "nfiles = len(files)\n",
    "print('{} files found in the data directory \\'{}\\'.'.format(nfiles, data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the data_dir and a file name, extract an image from\n",
    "# the set of images and the TICI score.\n",
    "# By default, nothing is printed.\n",
    "# If verbose=1, print the keys of the mat file content (which is a dictionary).\n",
    "# If verbose=2, print the 3 TICI scores for debugging purpose.\n",
    "def extract_data_file(data_dir, fname, verbose=False):\n",
    "    content = loadmat(os.path.join(data_dir, fname))\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('{}\\tkeys={}'.format(fname, sorted(content.keys())))\n",
    "    if verbose == 2:\n",
    "        print('{}\\t\\tTICI_Dr1={}\\tTICI_Dr2={}\\tTICI_report={}'.format(fname, content['TICI_Dr1'], content['TICI_Dr2'], content['TICI_report']))\n",
    "\n",
    "    raw_image_set, TICI = content['X'], content['TICI_report']\n",
    "    # Originally, raw_image_set[:, :, k] is the kth image.\n",
    "    # Reorder the dimensions such that raw_image_set[k, :, :] is the kth image.\n",
    "    image_set = np.transpose(raw_image_set, (2, 0, 1))\n",
    "    # Only one image from each image set is selected to be fed into the model.\n",
    "    # For simplicity, the image in the middle of each image set is selected just for now.\n",
    "    count, _, __ = np.shape(image_set)\n",
    "    image = image_set[count // 2]\n",
    "    return image, TICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fractals_1.mat\tkeys=['TICI_Dr1', 'TICI_Dr2', 'TICI_report', 'X', '__globals__', '__header__', '__version__']\n",
      "(1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# From the first mat file, learn the structure and the image set dimensions.\n",
    "# Assume that all mat files have the same structure and that all the images \n",
    "# in each image set have the same dimensions, though each image sets may\n",
    "# contain various number of images.\n",
    "sample_image, sample_TICI = extract_data_file(data_dir, files[0], verbose=1)\n",
    "image_shape = sample_image.shape\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fractals_1.mat\t\tTICI_Dr1=['2b']\tTICI_Dr2=['2b']\tTICI_report=['2a']\n",
      "fractals_10.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2a']\n",
      "fractals_100.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[3]]\n",
      "fractals_101.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_102.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2b']\n",
      "fractals_103.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[nan]]\n",
      "fractals_104.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2b']\n",
      "fractals_105.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_106.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=[[0]]\n",
      "fractals_107.mat\t\tTICI_Dr1=[[nan]]\tTICI_Dr2=[[nan]]\tTICI_report=['2a']\n"
     ]
    }
   ],
   "source": [
    "# For debugging purpose, print the 3 TICI scores for the first 10 mat files.\n",
    "for n in range(10):\n",
    "    _, _ = extract_data_file(data_dir, files[n], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 201 done\n",
      "10 / 201 done\n",
      "20 / 201 done\n",
      "30 / 201 done\n",
      "40 / 201 done\n",
      "50 / 201 done\n",
      "60 / 201 done\n",
      "70 / 201 done\n",
      "80 / 201 done\n",
      "90 / 201 done\n",
      "100 / 201 done\n",
      "110 / 201 done\n",
      "120 / 201 done\n",
      "130 / 201 done\n",
      "140 / 201 done\n",
      "150 / 201 done\n",
      "160 / 201 done\n",
      "170 / 201 done\n",
      "180 / 201 done\n",
      "190 / 201 done\n",
      "200 / 201 done\n",
      "(201, 1024, 1024)\n",
      "['2a', '2a', '3', '0', '2b', 'nan', '2b', '0', '0', '2a', '2b', '2a', '2a', '2b', '0', '2b', '2b', '0', 'nan', '3', 'nan', '2b', '1', '2b', '2a', '0', '2b', '2b', 'nan', '0', '2a', '0', '2a', '3', '2b', '2b', '2a', 'nan', '2b', 'nan', '0', '2a', '2a', '3', '2b', '2b', '0', '2b', '2b', '2b', '2a', '2a', '2b', '3', '2a', '2a', '2b', '2a', '2a', '2b', '2a', '2b', '2b', '0', '2a', '1', '2a', '2b', '3', '2a', '2a', '3', '0', '2a', '2a', '2b', '2b', '2a', '2a', '2b', '1', '2b', '3', '2a', '2b', '2a', '2b', '2b', '2a', '2a', 'nan', '0', '3', '2b', '0', '0', '0 (bilateral MCA)', '0', '0', '2b', '3', '3', '2b', '0', '2a', '2a', '0', '2a', '2b', '2a', '2b', '2b', '2b', '2b', '2b', '2a', '2b', '2a?', '2b', '0', '2a', 'nan', '2b', '2b', '2b', 'nan', '2a', '2a', '1', '2b', '2a', '1', '2b', '1', '1', '2b', '2a', 'nan', '2b', '2a', '2b', '2b', '2a', '2b', '2b', 'nan', '2b', '0', '2b', '0', '2b', '1', 'nan', '3', '2b', '2a', '2a', '2a', 'nan', '2b', '0', '3', 'nan', '0', '2b', '2a', '2b', '2b', '2b', '3', 'nan', '3', 'nan', 'nan', '2b', '2b', '3', '2a', '2a', '2b', '2b', '0', '0', '2a', '2a', '0', '2b', '2a', '2a', '2b', '2b', 'nan', 'nan', '0', 'nan', '2b', '2b', '2a', '2b', '2b', '2a']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list for images and a numpy arrays for \n",
    "# corresponding TICI scores. Assume all images have \n",
    "# the same dimensions. The TICI score in each \n",
    "images = []\n",
    "TICI_strings = []\n",
    "\n",
    "# Extract image and TICI information for all mat files.\n",
    "for n in range(nfiles):\n",
    "    # Print the extracting progress.\n",
    "    if n % 10 == 0:\n",
    "        print('{} / {} done'.format(n, nfiles))\n",
    "    image, TICI = extract_data_file(data_dir, files[n])\n",
    "    images.append(image)\n",
    "    # The TICI scores in the mat files are in the form of \n",
    "    # nested np.ndarray's of either strings, numbers, of nan.\n",
    "    # e.g., ['2a'], [[3]], [[nan]]. With assumption of \n",
    "    # this structure, simplify TICI before append it to TICIs.\n",
    "    while isinstance(TICI, np.ndarray):\n",
    "        TICI = TICI[0] if len(TICI) > 0 else ''\n",
    "    TICI_strings.append(str(TICI))\n",
    "\n",
    "print(np.shape(images))\n",
    "print(TICI_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat TICI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 4, 0, 3, 5, 3, 0, 0, 2, 3, 2, 2, 3, 0, 3, 3, 0, 5, 4, 5, 3, 1, 3, 2, 0, 3, 3, 5, 0, 2, 0, 2, 4, 3, 3, 2, 5, 3, 5, 0, 2, 2, 4, 3, 3, 0, 3, 3, 3, 2, 2, 3, 4, 2, 2, 3, 2, 2, 3, 2, 3, 3, 0, 2, 1, 2, 3, 4, 2, 2, 4, 0, 2, 2, 3, 3, 2, 2, 3, 1, 3, 4, 2, 3, 2, 3, 3, 2, 2, 5, 0, 4, 3, 0, 0, 0, 0, 0, 3, 4, 4, 3, 0, 2, 2, 0, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 0, 2, 5, 3, 3, 3, 5, 2, 2, 1, 3, 2, 1, 3, 1, 1, 3, 2, 5, 3, 2, 3, 3, 2, 3, 3, 5, 3, 0, 3, 0, 3, 1, 5, 4, 3, 2, 2, 2, 5, 3, 0, 4, 5, 0, 3, 2, 3, 3, 3, 4, 5, 4, 5, 5, 3, 3, 4, 2, 2, 3, 3, 0, 0, 2, 2, 0, 3, 2, 2, 3, 3, 5, 5, 0, 5, 3, 3, 2, 3, 3, 2]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The number of different TICI scores.\n",
    "# Including 0, 1, 2a, 2b, 3, nan.\n",
    "num_TICI_classes = 6\n",
    "\n",
    "# Convert a TICI string to a number\n",
    "def map_TICI_str_to_num(TICI):\n",
    "    relation = {\n",
    "        '0': 0,\n",
    "        '1': 1,\n",
    "        '2a': 2,\n",
    "        '2b': 3,\n",
    "        '3': 4,\n",
    "        'nan': 5,\n",
    "        '0 (bilateral MCA)': 0,\n",
    "        '2a?': 2\n",
    "    }\n",
    "    return relation[TICI]\n",
    "\n",
    "# Convert a numerical encoded TICI to a string\n",
    "def map_TICI_num_to_str(label):\n",
    "    relation = ['0', '1', '2a', '2b', '3', 'nan']\n",
    "    return relation[label]\n",
    "\n",
    "# Convert TICI scores in the form of strings to numeric labels before fed to the model.\n",
    "TICI_nums = list(map(map_TICI_str_to_num, TICI_strings))\n",
    "print(TICI_nums)\n",
    "\n",
    "# Convert the array of integer labels (0 ~ num_TICI_classes-1) to an array of \n",
    "# one-hot (aka one-of-K) encoded labels, for better accuracy.\n",
    "TICI_one_hot = keras.utils.to_categorical(TICI_nums, num_TICI_classes)\n",
    "print(TICI_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1024, 1024, 32)    832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1572870   \n",
      "=================================================================\n",
      "Total params: 1,625,094\n",
      "Trainable params: 1,625,030\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with tensorflow.keras.\n",
    "# The general idea is to reduce the size by maxpooling and \n",
    "# extract more features with convolutions of an increasing \n",
    "# number of filters.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 5, padding='same', activation='relu', \n",
    "                        input_shape=(image_shape[0], image_shape[1], 1)),  # learn why the 1 is required...\n",
    "    keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D((4, 4), (4, 4), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    # keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(num_TICI_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 1024, 1024, 1)\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 171s 853ms/sample - loss: 1.7601 - accuracy: 0.3781\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 164s 817ms/sample - loss: 1.5463 - accuracy: 0.3483\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 169s 842ms/sample - loss: 1.3301 - accuracy: 0.5025\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 163s 810ms/sample - loss: 1.0872 - accuracy: 0.5622\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 146s 729ms/sample - loss: 0.8285 - accuracy: 0.6816\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 145s 722ms/sample - loss: 0.6011 - accuracy: 0.7960\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 151s 750ms/sample - loss: 0.2965 - accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 141s 700ms/sample - loss: 0.3174 - accuracy: 0.8806\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 198s 986ms/sample - loss: 0.1931 - accuracy: 0.9502\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 181s 902ms/sample - loss: 0.0831 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f7a0e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add one dimension to the images input for channels.\n",
    "images_as_model_input = np.array(images).reshape(nfiles, image_shape[0], image_shape[1], 1)\n",
    "print(images_as_model_input.shape)\n",
    "model.fit(\n",
    "    x=images_as_model_input,\n",
    "    y=TICI_one_hot,\n",
    "    batch_size=4, ##################### TODO\n",
    "    epochs=10, ##################### TODO\n",
    "    verbose=1, # progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
